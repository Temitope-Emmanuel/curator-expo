
        // Suspend functionality
        const createAudioContext = async (base64String: any) => {

            const audioCtx = new AudioEngine.default.WebAudioContext({
                context: new AudioEngine.default.OfflineAudioContext()
            })
            const arrayBuffer = decode(base64String)

            const channels = 1;
            const frameCount = audioCtx.sampleRate * 1;

            // Add arrayBuffer to audioBuffer
            const createdBuffer = audioCtx.createBuffer(channels, frameCount, audioCtx.sampleRate)
            const nowBuffering = createdBuffer.getChannelData(0)
            for (let i = 0; i < createdBuffer.length; i++) {
                nowBuffering[i] = arrayBuffer[i]
            }

            // Create a buffer source

            const source = audioCtx.createBufferSource();
            const analyser = audioCtx.analyser;

            source.buffer = createdBuffer;
            source.connect(analyser)
            source.connect(audioCtx.destination)

            source.start()

            // console.log(createBuffer.length)

            // const view = new Uint8Array(arrayBuffer)
            // console.log(view.)
            // console.log("This is the view",{view})
            // const decodedData = await audioCtx.decodeAudioData(arrayBuffer)
            // console.log(JSON.stringify(arrayBuffer,null,2))
            // const audioBuffer = audioCtx.createBuffer(arrayBuffer)
            // console.log("this is the audioBuffer",audioBuffer.getChannel())
            // console.log(audioCtx.createBufferSource,audioCtx.createBuffer)


            // console.log("this is the arrayBuffer",decodedData)
            // console.log("This is the new Response",{newResponse})

            // audioCtx.decodeAudioData(base64String).then(response => {
            //     console.log("this is the response",{response})
            // })

            // console.log(base64String)
            // const analyser = audioCtx.createAnalyser()
            // const dataArray = new Float32Array(analyser.frequencyBinCount)
            // console.log(audioCtx.decodeAudioData)

            // const AudioCtx = AudioEngine.WebAudioContext
            // const audioCtx = new AudioCtx({
            //     context:new AudioCtx(),
            //     destination:undefined
            // })

            // console.log({audioCtx})
            // const audioData = audioCtx.exportAsAudioData();
            // const analyser = audioCtx.createAnalyser()
            // console.log("this is the audioCtx",JSON.stringify(audioData,null,2))
            // const dataArray = new Float32Array(analyser.frequencyBinCount)
            // const source = audioCtx.createMediaStreamSource(base64String)
            // console.log("this is the dataArray",{source})
            // source.connect(analyser)

            // analyser.getFloatTimeDomainData(dataArray)

            // console.log("this is the data array",{dataArray})
        }







        import React from "react"
import { Box, Center, Pressable } from "native-base"
import {TabView, SceneMap, SceneRendererProps, NavigationState} from "react-native-tab-view"
import { Dimensions, StatusBar, Animated } from "react-native"
// import Animated from "react-native-reanimated"


const FirstRoute = () => (
    <Center flex={1}>
        This is Tab 1
    </Center>
)
const SecondRoute = () => (
    <Center flex={1}>
        This is Tab 2
    </Center>
)
const ThirdRoute = () => (
    <Center flex={1}>
        This is Tab 3
    </Center>
)
const initialLayout = {
    width:Dimensions.get("window").width
}
const renderScene = SceneMap({
    first:FirstRoute,
    second:SecondRoute,
    third:ThirdRoute
})





const PlaylistTabView = () => {
    const [index,setIndex] = React.useState(0);
    const [routes] = React.useState([
        { key: 'first', title: 'Tab 1' },
        { key: 'second', title: 'Tab 2' },
        { key: 'third', title: 'Tab 3' },
      ]);

      const renderTabBar = (props: SceneRendererProps & {
        navigationState: NavigationState<any>;
    }) => {
        const inputRange = props.navigationState.routes.map((item,idx) => idx)
          return(
            <Box flexDirection="row">
                {props.navigationState.routes.map((route,i) => {
                    const opacity = props.position.interpolate({
                        inputRange,
                        outputRange: inputRange.map((inputIdx) => inputIdx === i ? 1 : 0.5)
                    })
                    const color = index === i ? "#1f2937" : "#a1a1aa";
                    const borderColor = index === i ? "cyan.500" : "coolGray.200"

                    return(
                        <Box p="3" cursor="pointer"
                            borderBottomWidth="3" flex={1}
                            borderColor={borderColor} alignItems="center"
                        >
                            <Pressable onPress={() => {
                                console.log("this is i",{i})
                                setIndex(i)
                            }} >
                                <Animated.Text
                                    style={{color}}
                                >
                                    {route.title}
                                </Animated.Text>
                            </Pressable>
                        </Box>
                    )
                })
            }
            </Box>
          )
      }
      
      return(
        <TabView
        navigationState={{index,routes}}
        renderScene={renderScene}
        renderTabBar={renderTabBar}
        onIndexChange={setIndex}
        initialLayout={initialLayout}
        style={{
            marginTop:StatusBar.currentHeight
        }}
        />
      )
}

export default PlaylistTabView